 

 

 



 
				<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
									  "DTD/xhtml1-transitional.dtd">
				<html>
					<head>
						<title>PROMISE data</title>
						<link 	rel="stylesheet" href="http://promisedata.org/img/screen.css" 
								media="screen" type="text/css" />
						<link 	rel="stylesheet" href="http://promisedata.org/img/print.css"  
								media="print"  type="text/css" />
					</head>
					<body>
						<div id="top"><a name="top"></a>    
<h1><strong>The PROMISE'07<br>WORKSHOP- May 20, 2007</strong></h1>
<p>To be held with <a href="http://web4.cs.ucl.ac.uk/icse07/">ICSE 2007</a>, Minneapolis, MN, USA </div> 					
 
						<div id="div18">   
<h1><img align=left src="http://promisedata.org/img/warning.gif">Public Data Policy</h1>
 
<p>PROMISE 2007 gives <b>the highest priority</b> to case studies,
experience reports, and presented results that are based
on publicly available datasets. To increase the chance
of acceptance, authors are urged to submit papers that
use such datasets.  Data can come from anywhere including
the workshop Web site. Such papers should include the URL
address of the dataset(s) used.</p>

<p>A copy of the public datasets used in the accepted papers
will be posted on <a href="http://promisedata.org/repository">the PROMISE Software Engineering
Repository</a>. Therefore, if applicable, the authors should
obtain the necessary permission to donate the data prior
to submitting their paper. All donors will be acknowledged
on the PROMISE repository Web site.</p>
    </div>
						<div id="div44"> 								
 


<img width=150 align=right src="../img/goals.gif">
<h1><strong>Goals</strong></h1>
<ul><li> To expand the current public repository of data sets
  related to software engineering in order to conduct repeatable,
  refutable or improvable experiments (the 
current <a href="http://promisedata.org/repository">PROMISE
  repository</a> already contains 24 data sets).
</li>
 
<li> To deliver to the software engineering community useful
  and usable and verified models or methods:
<ul><li> 
   <em>Models</em> predict software properties of interest to
    21st century software practitioners. 
 </li>
  <li><em>Methods</em> are learning systems for building particular
    models for particular situations.
  </li></ul></li>
<li> To compile a list of open research questions that are
  deemed essential by the researchers in the field.
 </li>
<li> To show, by example, to the next generation of software
  engineering researchers that empiricism is useful,
  practical, exciting, and insightful.
</li> 
<li> To bring together researchers and practitioners with
  the aim of sharing experience and expertise.
</li> 
<li> To steer discussion and debate on various aspects and
  issues related to building predictive software models.
</li>
<br>
<img src="http://promisedata.org/img/dots.png">
</ul>
 
<img align=right width=150
src="../img/lib.jpg">
<h1><strong>Journal issue</strong></h1>
<p>Papers accepted to PROMISE 2007 (and 2006) will be
eligible for submission to a special issue of the Journal
of Empirical Software Engineering on repeatable experiments
in software engineering.
 </p><p>
The issue will be edited by Tim Menzies. 
<br><img src="http://promisedata.org/img/dots.png">
</p>

<img align=right width=150
src="../img/topic.jpg">
<h1><strong>Topics</strong></h1>

<ul><li> Applications of predictive models to software
  engineering data.
 </li><li>
 What predictive models can be learned from
  software engineering data?
</li><li> 
 Strengths and limitations of predictive models.
<li> 
 Empirical Model Evaluation Techniques.
<ul><li>   What are best baseline models for different classes of
    predictive software models?
  </li><li> Are existing measures and techniques to evaluate
    and compare model goodness (e.g. precision, recall,
 error rate, ROC analysis)  adequate for evaluating software
    models? Or are more specific measures geared toward
    software engineering domain needed?

  </li><li> Are certain measures better suited for certain
    classes of models?
  </li><li> What are the appropriate techniques to test the
    generated models e.g. hold-out, cross-validation, or
 chronological splitting?
</li></ul> </li>
<li>
 Field evaluation challenges and techniques.
<ul><li>  What are the best practices in evaluating the generated
     software models in the real world?
</li><li>   What are the obstacles in the way of field testing a
    model in the real world?
  </li><li> How to overcome obstacles in the acceptance of
    predictive models in the real world?
</li>
<li> 
How to test the generated models?
</li>
<li> 
 What are the obstacles in the way of field testing
  a model in the real world?
<ul><li>
   What predictive models are more prone to
    model shift? (Concept drift).
  </li><li> When does a model need to be replaced?
  </li><li> What are the best approaches to keeping the model
    in sync with software changes?
</li></ul> </li></ul>
<li> Building models using machine learning, statistical
  methods, and other methods.
  <ul><li> How do these techniques lend themselves to building
    predictive software models?
  </li><li> Are some methods better suited for certain
    classes of models?
  </li><li> How do these algorithms scale up when handling
    very large amounts of data?
  </li><li> What are the challenges posed by the nature of data
    stored in software
    repositories that make certain techniques less
    effective than the others?
</li></ul></li> 
<li> Cost benefit analysis of predictive models
  <ul><li> Is cost-benefit analysis a necessary step in evaluating
    all predictive models?
 </li><li> What are the requirements for one to be able to perform
    a cost benefit analysis?
  </li><li> What particular costs and benefits should be considered
    for these models?
  </li></ul></li> 
<li>
 Case studies on building predictive software models.
</li>
<br><img src="http://promisedata.org/img/dots.png">
</ul>
<img align=right width=150 src="../img/survey.jpg">
<h1><strong>Benchmarks </strong></h1>

<p> 
To encourage data sharing and/or publicize new and
challenging research direction, a special category of
papers will be considered for inclusion in the workshop.
Papers submitted under this category should at least
include the following information:
</p>
<ul> 
<li> The public URL to a new dataset
</li><li> Background notes on the domain
</li><li> What problem does the data represent?
</li><li> What would be gained if the problem was solved?
</li>
<li>Proposes a measure of goodness to be used to judge the
  results; for instance a good defect detector has a
  high probability of detection and a low probability
  of false alarm.
</li>
<li>
A review of current work in the field (e.g. what is
  wrong with current solutions or why has no one solved
  this problem before?)
</li>
<li>Preferably some baseline results.</li>
<li> 
Description of data format.
The  
   recommended format is <a href="http://www.cs.waikato.ac.nz/~ml/weka/arff.html">Attribute-Relation File Format (ARFF)</a>.
   For an example of such a dataset see
     <em>Cocomo NASA/Software cost estimation</em>
   on the <a href="http://promisedata.org/repository">PROMISE Software Engineering Repository</a>.
   However, if ARFF is not an appropriate format for
   your data, please provide a detailed description of
   your data format in the paper.  A guideline from UCI
   Machine Learning repository for documenting datasets
   can be found in
     <a href="ftp://ftp.ics.uci.edu/pub/machine-learning-databases/DOC- REQUIREMENTS">ftp://ftp.ics.uci.edu/pub/machine-learning-databases/DOC- REQUIREMENTS</a>.
   This information is placed before the actual data
   when using ARFF format.  However, if you are using an
   alternative format that does not support comments in
   the dataset, provide this information in a separate file
   with extension .desc, and submit the URL of this file.
</li>
<br><img src="http://promisedata.org/img/dots.png">
</ul> 

<a name="submission"></a> <a href="http://www.easychair.org/PROMISE2007/"><img width=150  align=right
src="http://www.dodsbir.net/submission/image/e-submit.gif" border=2></a>
<h1><strong>Submission </strong></h1>

<p>
<b>Submissions to PROMISE 2007 are now closed. Please see
the <a href="schedule.html">list of accepted papers</a></b>
</p>

<!-- 
<font color=gray>
<p>Submissions are five to ten pages long (max). Papers must
be original and previously unpublished. SUBMISSIONS WHICH
INCLUDE EMPIRICAL RESULTS BASED ON PUBLICLY ACCESSIBLE
DATASETS WILL BE GIVEN THE HIGHEST PRIORITY.
</p>
<p> 
Accepted papers and other materials for the Proceedings
must be revised to conform to the <a href="http://web4.cs.ucl.ac.uk/icse07/index.php?id=79">ICSE IEEE style guidelines</a>
(see the heading <b>Paper Format Information</b>).
Accepted file formats are Postscript and PDF. 
</p>
<p> 
To submit papers:
<ul>

  <li> Go to
  		<a href="http://www.easychair.org/PROMISE2007/">http://www.easychair.org/PROMISE2007/</a>.
<li>Create an EasyChair account.
  <ul><li>
  Please note that it takes                          
  about 10 minutes to fill out the form and get an email that acknowledges the activation of
  	your EasyChair account.
	</li>
		</ul>
	<li>Once you get notice of your EasyChair account activation, login to EasyChair and follow the
instructions to submit. <ul><li>Be sure to identify your submission as either a Regular Paper
or a Benchmark.
</li></ul>
</ul> 
<p>
Each paper will be reviewed by the program committee in
terms of their technical content and their relevance to
the scope of the workshop, as well as its ability to
stimulate discussion. At least one author of accepted
papers is required to register and attend the workshop.
</p> 
<p>Prior to the workshop the accepted papers will be posted
on this web site.
<br><img src="http://promisedata.org/img/dots.png">
</p>
</font>
-->
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
 
						<div id="footer"> 
	Copyright 2006,2007 the PROMISE group ~ Design by Ellen B. Edgerton
 </div> </div>
						<div id="div19"> 
<div class="banner">Contact us</div>
<p align=center><a href="mailto:2007@promisedata.org">2007@promisedata.org</a>
</p>
<div class="banner">Important dates</div>
<br><p><em>Submission : </em>    Jan.  20, '07<br>
<em>Notification : </em>  Feb. 10, '07<br>
<em> Camera ready:  </em>         Mar 5, '07<br>
</p><br>
<div class="banner">General Chair</div>
<ul><li> <em>Gary Boetticher</em><br>     U. of Houston- Clear Lake</li></ul>
 
<div class="banner">Steering Committee</div>
<ul><li><em>Gary Boetticher</em><br>     U. of Houston - Clear Lake</li>
<li><em>Tim Menzies </em>     <br>   West Virginia U.,US</li>
<li>	<em>Tom Ostrand  </em>   <br>    AT&T</li>
</ul> 
<div class="banner">Program Committee</div>
<ul>
<li><em>Vic Basili</em><br> U. Maryland,US</li> 
<li><em>Dan Berry   </em><br>       U. Waterloo,Canada</li> 
<li><em>Barry Boehm  </em><br>      U. Southern California,US</li> 
<li><em>Gary Boetticher</em><br>    U. of Houston- Clear Lake,US</li> 
<li><em>Lionel Briand</em><br>      Carleton U.,Canada</li> 
<li><em>Bojan Cukic  </em><br>      West Virginia U.,US</li> 
<li><em>Alex Dekhtyar</em><br>      U. Kentucky,US</li> 
<li><em>Martin Feather</em><br>     NASA JPL,US</li> 
<li><em>Norman Fenton</em><br>      Queen Mary (U. of London),UK</li> 
<li><em>Jane Hayes</em><br>         U. Kentucky,US</li> 
<li><em>Jairus Hihn</em><br>        NASA JPL's Deep Space Network,US</li> 
<li><em>Gunes Koru </em><br>        U. of Maryland,Balt. Cty,US</li> 
<li><em>Tim Menzies</em><br>        West Virginia University,US</li> 
<li><em>Martin Neil </em><br>       Queen Mary(U. of London),UK</li> 
<li><em>Allen Nikora </em><br>      NASA JPL,US</li> 
<li><em>Tom Ostrand </em><br>       AT&T,US</li> 
<li><em>Daniel Port </em><br>       U. Hawaii,US</li> 
<li><em>Julian Richardson</em><br>  NASA ARC,US</li> 
<li><em>Guenther Ruhe </em><br>     U. Calgary,Canada</li> 
<li><em>Martin Shepperd</em><br>    Brunel U.,UK</li> 
<li><em>Forrest Shull </em><br>     Fraunhofer Centre Maryland,US</li> 
<li><em>Willem Visser </em><br>     NASA ARC,US</li> 
<li><em>Elaine Weyuker </em><br>    AT&T,US</li> 
<li><em>Laurie Williams </em><br>   North Carolina State U.,US</li> 
<li><em>Marv Zelkowitz  </em><br>   U. of Maryland,US</li> 
<li><em>Du Zhang </em><br>          Cal. State Univ., Sacramento, USA
</ul>
 </div> 					
 
						<div id="div13"> 
	<h1>Links</h1>
		<div id="navigation">
			<ul>
				<li><a href="http://promisedata.org">Home</a></li>
				<li><a href="mailto:mail@promisedata.org">Contact us</a></li>
    			<li><a href="http://promisedata.org/repository">Data repository</a></li>
		</ul>
	<p>&nbsp;</p>
		<h1>Workshops:</h1>
		<ul>
    			<li><a href="http://promisedata.org/repository/papers.html">On-line papers</a></li>
			
				<li> <a href="http://promisedata.org/2008/CFP.html">PROMISE '08</a></li>
		<li> <a href="http://promisedata.org/2007">PROMISE '07</a></li>
				<li> <a href="http://unbox.org/promise/2006">PROMISE '06</a></li>
	
			</ul>
		</div>
 </div>
	 				</body>
				</html> 												
 