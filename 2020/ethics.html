<p>
<-- p>Ethically-oriented papers:
<ul>
<li>It is encouraged,
<span style="background-color: #ADFF2F;">
but not mandatory, 
</span>
that somewhere in their paper
authors make some comment about the question posed above:
<ul><em>
Can we now apply and adjust our AI-for-SE tools (including predictive models)
to handle ethical non-functional requirements such as
inclusiveness, transparency, oversight and accountability,
privacy, security, reliability, safety, diversity and fairness? 
</em></ul>
<li>For some notes on these ethical non-functional requirements,
see our section  <a href="#ethics">"Notes on ethics"</a>.
</ul --->
<-- a name=ethics><h3>Notes on Ethics</h3></a>
<p>
<img align=right width=500 style="padding: 5px;" src="https://github.com/promiseconf/promiseconf.github.io/raw/master/2020/img/ethics.jpg">
    	 Many large international organizations are demanding
	 that AI models do more than just predict things. Now, it is expected
	 that they also contribute to other non-functional requirements.
	 <ul>
	 <li> In their document <a href="https://ethicsinaction.ieee.org">Ethically Aligned Design</a>, the IEEE lists these
	 goals for  implementing autonomous and intelligent systems (A/IS):
<ul>
	 <li><em>Human Rights:</em> A/IS shall be created and operated to respect, promote, and protect internationally recognized human rights.
	 <li><em>Well-being:</em> A/IS creators shall adopt increased human well-being as a primary success criterion for development.
	 <li><em>Data Agency:</em> A/IS creators shall empower individuals with the ability to access and securely share their data, to maintain peopleÃÂ¢ÃÂÃÂs capacity to have control over their identity.
	 <li><em>Effectiveness:</em> A/IS creators and operators shall provide evidence of the effectiveness and fitness for purpose of A/IS.
	 <li><em>Transparency:</em> The basis of a particular A/IS decision should always be discoverable.
	 <li><em>Accountability:</em> A/IS shall be created and operated to provide an unambiguous rationale for all decisions made.
	 <li><em>Awareness of Misuse:</em> A/IS creators shall guard against all potential misuses and risks of A/IS in operation.
</ul>

<li>Other organizations, like 
<a href="https://github.com/txt/ase19/blob/master/docs/REFS.md#microai-2019">Microsoft</a> offer their own principles for AI:
<ul>
<li><em>Transparency:</em> AI systems should be understandable
<li><em>Fairness:</em> AI systems should treat all people fairly
<li><em>Inclusiveness:</em> AI systems should empower everyone and engage people
<li><em>Reliability & Safety:</em> AI systems should perform reliably and safely
<li><em>Privacy & Security:</em> AI systems should be secure and respect privacy
<li><em>Accountability: </em> AI systems should have algorithmic accountability
</ul>
<li> Another statement of required ethics from AI systems comes from the 
<a href="https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai">European Union</a>:
<ul>
<li><em>Human agency and oversight:</em> AI systems should empower human beings, allowing them to make informed decisions and fostering their fundamental rights. At the same time, proper oversight mechanisms need to be ensured, which can be achieved through human-in-the-loop, human-on-the-loop, and human-in-command approaches
<li><em>Technical Robustness and safety:</em> AI systems need to be resilient and secure. They need to be safe, ensuring a fall back plan in case something goes wrong, as well as being accurate, reliable and reproducible. That is the only way to ensure that also unintentional harm can be minimized and prevented.
<li><em>Privacy and data governance:</em> besides ensuring full respect for privacy and data protection, adequate data governance mechanisms must also be ensured, taking into account the quality and integrity of the data, and ensuring legitimised access to data.
<li><em>Transparency:</em> the data, system and AI business models should be transparent. AI systems and their decisions should be explained in a manner adapted to the stakeholder concerned. Humans need to be aware that they are interacting with an AI system, and must be informed of the system's capabilities and limitations.
<li><em>Diversity, non-discrimination and fairness:</em> Unfair bias must be avoided, as it could could have multiple negative implications, from the marginalization of vulnerable groups, to the exacerbation of prejudice and discrimination. Fostering diversity, AI systems should be accessible to all, regardless of any disability, and involve relevant stakeholders throughout their entire life circle.
<li><em>Societal and environmental well-being:</em> AI systems should benefit all human beings, including future generations. It must hence be ensured that they are sustainable and environmentally friendly. Moreover, they should take into account the environment, including other living beings, and their social and societal impact should be carefully considered.
<li><em>Accountability:</em> Mechanisms should be put in place to ensure responsibility and accountability for AI systems and their outcomes. Auditability, which enables the assessment of algorithms, data and design processes plays a key role therein, especially in critical applications. Moreover, adequate an accessible redress should be ensured.
</ul>
	 </ul>
<p>
<img align=right width=500 src="https://github.com/promiseconf/promiseconf.github.io/raw/master/2020/img/ethics1.png">
Ethics is a rapidly evolving concept so it hardly surprising to say that mapping the stated ethical concerns of one organization into another is not easy. Nevertheless, the following tables shows one way we might map together these three sets of ethical concerns. Note that:

<ul>
<li>"accountability" and "transparency" appear in all three statements. Clearly these are concerns shared by many people.
<li>Missing from the Microsoft list is "effectiveness". Maybe Microsoft always assumes that their software is always effective?
<li>Assessed in terms of the Microsoft terminology, the IEEE goals or "well-being" and "awareness of misuse" are synonyms since they both reply on "fairness and "reliability and safely".
</ul --->

