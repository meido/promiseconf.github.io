<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>PROMISE 2020: The International Conference on Predictive Models and Data Analytics in Software Engineering </title>
<meta name="description" content="PROMISE 2020: The International Conference on Predictive Models and Data Analytics in Software Engineering">
<meta name="keywords" content="PROMISE,predictive models,data analytics,software engineering">
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
<link href="img/3-col-fluid.css" rel="stylesheet" type="text/css" />
<link href="img/print.css" rel="stylesheet" type="text/css" media="print"/>

 <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Open Sans">
  

<!-- Please feel free to use this code in any way that you would like.  If you want to be cool, you can credit me - Mani Sheriar | www.ManiSheriar.com | Design@ManiSheriar.com.  Enjoy! -->

</head>

<body>
  <div id="outer">
    
  <div id="header"><!-- begin header -->
    
   <h1>PROMISE 2020</h1>
  <p>Inventing what's next  in software analytics<br> 
  An <a href="https://www.cs.ucdavis.edu/fse2020">FSE'20</a> co-located event.<br>
  http://tiny.cc/promise20<br>
  Nov 5-6, 2020<br>
    
  </div><!-- end header -->
<div id=menu>

	<div id="tabs4">
		<ul>
			<li><a href="https://www.cs.ucdavis.edu/fse2020/attending/venue/"><span><img src="https://www.freeiconspng.com/uploads/google-location-icon-16.png" align=top height=18> Venue</span></a></li>
			<li><a href="#keynotes"><span>Keynotes</span></a></li>
			<li><a href="#cfp" ><span>CFP</span></a></li>
			<li><a href="#special" ><span>Special issue </span></a></li>
			<li><a href="#submit" ><span>Submit</span></a></li>
			<li><a href="#program" ><span>Program </span></a></li>
			<li><a href="#history" ><span>History</span></a></li>
			<li><a href="img/promise20.pdf" ><span>Download flyer <img src="https://cdn.pixabay.com/photo/2016/06/15/14/54/download-1459070_960_720.png" align=top height=18></span></a></li>
			<li><a href="mailto:timm@ieee.org" ><span>Contact</span></a></li>
		</ul>
	</div>     
</div>
<div id="wrapper1"><!-- sets background to white and creates full length leftcol-->
	
	<div id="wrapper2"><!-- sets background to white and creates full length rightcol-->
	
		<div id="maincol"><!-- begin main content area -->
				
		  <div id="leftcol"><!-- begin leftcol -->
<center>
	<p>
	<a href="https://promise20.hotcrp.com/paper/new"><img src="img/submit.png" width=200></a>
	</p></center>
	  
			  

<ul>
<li><strike>Submission: June 30, 2020</strike>
<li>Submission: July 8, 2020
<li>Notification: Aug 4
<li>Camera ready: Aug 30
<li>Meeting: Nov 5-6
			    </ul>
		    <center>
		   
		    <time datetime="2014-09-20" class="icon">
		      
		      <span>5-6</span>
		 
  <strong>November</strong>
     </time>
		    </center>
	
<hr>
<center>
<a name="keynotes"><h3>Keynote Speakers</h3></a>
<small>
<p><img width=120 xalign=left style="padding: 5px;" src="img/bellamy.png"><br>
<b>Rachel Bellamy</b><br> IBM Research, NY:
<em>"Fair AI in Practice"</em><br>

<p><img width=120 ixalign=left style="padding: 5px;" src="img/briand.png"><br>
<b>Lionel Briand</b><br> U.Ottawa, Canada:
<em>"Natural Language and Software Requirements"</em><br>
</center>

<p>&nbsp;
<p><b><a name="bellamy">Dr. Rachel Bellamy: Fair AI in Practice</a></b>.
Fairness is an increasingly important concern as machine learning
models are used to support decision making in high-stakes applications
such as mortgage lending, hiring, and prison sentencing. This talk
will introduce an open source Python toolkit for algorithmic fairness,
AI Fairness 360 (AIF360). The main objectives of this toolkit are
to help facilitate the transition of fairness research algorithms
to use in an industrial setting and to provide a common framework
for fairness researchers to share and evaluate algorithms.
<em>Dr. Bellamy  is a Principle Research Scientist and manages
 the Human-AI Collaboration group at IBM T J Watson Research Center,
 Yorktown Heights, New York
Her team is currently working on the user experience for several
of IBM's AI projects, including the AI Fairness 360 toolkit
and rule-based machine-teaching for Watson Assistant. Rachel received
her doctorate in cognitive psychology from University of Cambridge,
UK in 1991. She holds many patents and has published more
than 70 research papers. For more, see her 
<a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-rachel">website</a>.
</em>

<p><b><a name="briand">Dr. Lionel Briand: NLP and Requirements</a></b>
Abstract, to be confirmed.
<em>
 Lionel C. Briand is professor of software engineering and has
 shared appointments between (1) The University of Ottawa, Canada
 and (2) The SnT centre for Security, Reliability, and Trust,
 University of Luxembourg. One of the founders of
 the 
 ICST conferencea
ge was also EiC of Empirical Software
 Engineering (Springer) for 13 years.
 Lionel was elevated to the grade of IEEE Fellow in 2010 for his
 work on testing object-oriented systems. He received an ERC
 Advanced grant in 2016- on the topic of modelling and testing
 cyber-physical systems- which is the most prestigious individual
 research award in the European Union. Most recently, he was awarded
 a Canada Research Chair (Tier 1) on "Intelligent Software Dependability
 and Compliance". His research interests include: software testing
 and verification, model-driven software development, applications
 of AI in software engineering, and empirical software engineering.
For more, see his <a href="https://sites.google.com/svv.lu/briand">website</a>.
</em>

	<hr>
	<center>
<a name=special><h3>Special Issue (at EMSE)</h3></a>
</center>
      	      <img width=80 align=right style="padding: 5px;" src="https://images.springer.com/sgw/journals/medium/10664.jpg">

<p>
<b>Inventing the next generation of software analytics.</b>

<p>Following on from this conference, we are organizing a 
special issue of the Empirical Software Engineering Journal.
<p>We
will ask authors
to comment on the success and failings of software analytics
over the last 20 years and will ask
"what and how can we do it better in future?". It is encouraged,
but not mandatory that authors 
explore the ethical issues raised in our CFP.

<p>The special issue will have the same guest editors as the co-PC chairs
of this conferences. Where possible, that special issue will also try to
use the same reviewers as PROMISE'20. The special issue will be open to
the entire SE community.

<p>Note that any PROMISE conference paper submitted to the special issue must be a 
significant extension to original conference content.

</small>			  
		  

				
				  </div><!-- end leftcol -->
				
			<div id="rightcol"><!-- begin rightcol -->
<center>
			  
<img src="img/p20.png" height=130>

<h3>ORGANIZING COMMITTEE </h3>
<small>
<b>general chair:</b>
<a href="http://www.cs.bham.ac.uk/~minkull/">Leandro Minku</a>, UK<br>
<b>co-pc-chairs:</b>
<a href="http://menzies.us">Tim Menzies</a>,   USA<br>
and <a href="https://cs.uwaterloo.ca/~m2nagapp/">Mei  Nagappan</a>,    Canada
<!-- p><img src="img/minku.png" height=60>
 <img src="img/timm.png" height=60>&nbsp;&nbsp;&nbsp;<img src="img/mei.png" height=60 -->
<br><b>proceedings:</b>
<a href="http://www.research.lancs.ac.uk/portal/en/people/david-bowes(e0869507-92eb-4d5b-bbf9-af5f0ffe143c).html">David Bowes</a>, UK<br>
<b>publicity:</b>
<b></b><a href="https://www.igor.pro.br">Igor Steinmacher</a>,  USA<br>
and <b></b><a href="https://research.monash.edu/en/persons/xin-xia">Xin Xia</a>, AUS<p>
<!-- img src="img/bowes.png" height=60>
<img src="img/igor.png" height=60>
<img src="img/xin.png" height=60 -->
 </p>
 
			    <h3>
			    Replication challenge track</h3><p>
			    Michael Hilton, CMU<br>
			    Gema Rodriguez-Perez, U. Waterloo</p>

			      
			    <h3>Program Committee</h3>
	<table style="border:0;cell-padding:0; border-spacing: 0px; border-collapse:collapse;">
	
    <tr><td>Ho Khanh Dam </td><td> U.Woolongong, Aus</td></tr>
    <tr><td>Giuseppe Destefanis</td><td> Brunel, UK</td></tr>
    <tr><td>	 Carmine Gravino</td><td> U. Salerno, Italy</td></tr>
<tr><td>	 Tracy Hall</td><td>	 U. Lancaster, UK</td></tr>
<tr><td>	 Rachel Harrison</td><td>	 Oxford Brooks, UK</td></tr>
<tr><td>	 Yasutaka Kamei </td><td>	Naoyasu U., Japan</td></tr>
<tr><td>	 Lech Madeyski</td><td>	Wroclaw U., Polsand	</td></tr>
<tr><td>	 Shane McIntosh</td><td>	McGill U, Canada	</td></tr>
<tr><td>	 Jaechang Nam</td><td>	HGU,   Sth.Korea</td></tr>
<tr><td>	 Maleknaz Nayebi</td><td>	U.Toronto, Canada</td></tr>

<tr><td>	 Fabio Palomba</td><td> U.Zurich, Switzerland</td></tr>
<tr><td>	 Daniel Rodriguez</td><td>	U.   Alcala,  Spain	</td></tr>
<tr><td>	 Martin Shepperd</td><td> Brunel U., UK</td></tr>

<tr><td>			Jeff Tian</td><td>	Sth. Methodist U., USA</td></tr>
<tr><td>			Ayse Tosun</td><td>	ITU, Turkey</td></tr>

<tr><td>					Hironori Washizaki</td><td> Waseda U., Japan	</td></tr>
<tr><td>					Xin Xia</td><td>	Monash U, Australia		</td></tr>
<tr><td>					Zhou Yuming</td><td> Nanjing University, China</td></tr>
<tr><td>					and others</td><td> TBD</td></tr>
</table>

<h3>Steering Committee</h3>
</center>
        <ul>
          <li>General chair:
         <a href="http://www.cs.bham.ac.uk/~minkull/" target="_blank">Leandro Minku</a>, U.Birmingham</li>

          <li><a href="" target="_blank">David Bowes</a>, U.&nbsp;Lancaster</li>
	  <li><a href="http://www.khomh.net/">Foutse Khomh</a>, Ecole Polytechnique de Montreal</li>
          <li><a href="http://shanemcintosh.org/" target="_blank">Shane McIntosh</a>, McGill U.</li>
          <li><a href="http://www.cs.bham.ac.uk/~minkull/" target="_blank">Leandro Minku</a>, U. Birmingham</li>    
	  <li><a href="https://www.lancaster.ac.uk/scc/about-us/people/jean-petric">Jean Petric</a>, Lancaster University</li>
          <li><a href="https://web.itu.edu.tr/~tosunay/" target="_blank">Ayse Tosun</a>, Istanbul Tech.U.</li>
</ul>


   </center> 

<hr>
	

<a class="twitter-timeline" data-tweet-limit="10" data-chrome="nofooter noborders noscrollbar " href="https://twitter.com/promise_conf" data-widget-id="595679308884082688">Tweets by 
@promise_conf</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>

			  
			</div><!-- end righttcol -->
	</small>		
			<div id="centercol"><!-- begin centercol -->

			  <a name=about></a>

			  <h3>Covid-19 notice</h3> <p>Due to covid-19, PROMISE'20 will be a fully virtual event, co-located with FSE. Further information will follow soon.</p><hr>
			  
			  
<p>  
For decades, 
<a href="#history">PROMISE has lead the SE field in open science</a>.
Here, we place a high premium on work
that can be repeated and/or improved and/or refuted by other researchers.
Hence we focus on those conclusions that can be reached automatically, via data mining.
Also, we strongly suggest that PROMISE authors share their
tools and data.  
<!-- p>
Our  theme for PROMISE'20 is  <u>Ethical AI</u>.  
Models generated by AI-for-SE tools 
are 
assessed  by their predictive performance (via accuracy, recall, etc).
But groups like
the
IEEE, the Europeran Union, and Microsoft
now demand we
<a href="#ethics">assess
our tools using other
ethical criteria</a>. Hence, 
PROMISE'20 asks:
<ul><em>
Can we now apply and adjust our AI-for-SE tools (including predictive models)
to handle ethical non-functional requirements such as
inclusiveness, transparency, oversight and accountability,
privacy, security, reliability, safety, diversity and fairness? 
</em></ul>
<p>
To support our PROMISE'20 theme on Ethical AI:
<ul>
<li>We ask PROMISE'20 authors
to offer one (or more) section(s) in their paper on how their technology comments on ethical
non-functional requirements. 
For more details on thse kinds of requirements, see 
<a href="#ethics">notes on ethics</a>, below.
<span style="background-color: #ADFF2F;">This request is optional: PROMISE'20 is also 
	a venue for 
T
"classic" PROMISE research that explores predictive modeling</span>.
	<li> We have invited keynote speakers to address
these broader issues of AI-for-SE tools. 
<li> We are planning a lively "fish-bowl panel"
for this meeting where all participants can comment on ethics and AI-for-SE. </p -->

<p> This meeting will be followed by a <a href="#special">special issue of the Empirical Software Engineering journal</a>,
focusing on the issues of this conference.
</p>


<hr>
<h3>Accepted Papers</h3>
  <div style="margin-top: 1em;">
      <span
        title=""
      >

          <span style="font-size: 100%">
            Software Defect Prediction using Tree-Based Boosting Ensembles
          </span>

      </span>
      <br />
      Hamoud Aljamaan and Amal Alazba<br />
      <i><small>(King Fahd University of Petroleum and Minerals, Saudi Arabia; King Saud University, Saudi Arabia)</small></i><br />
      <span id="fsews20promisemain-p14-p-abs" style="display:none; border:1ex solid transparent; font-size: smaller;" >
              <br/>
        <br />
      </span>
     

  </div>
  <div style="margin-top: 1em;">
      <span
        onclick="toggle('fsews20promisemain-p16-p-abs')" 
        title="Background: Reviewer recommendation approaches have been proposed to provide automated support in finding suitable reviewers to review a given patch. However, they mainly focused on reviewer experience, and did not take into account the review workload, which is another important factor for a reviewer to decide if they will accept a review invitation. Aim: We set out to empirically investigate the feasibility of automatically recommending reviewers while considering the review workload amongst other factors. Method: We develop a novel approach that leverages a multi-objective meta-heuristic algorithm to search for reviewers guided by two objectives, i.e., (1) maximizing the chance of participating in a review, and (2) minimizing the skewness of the review workload distribution among reviewers. Results: Through an empirical study of 230,090 patches with 7,431 reviewers spread across four open source projects, we find that our approach can recommend reviewers who are potentially suitable for a newly-submitted patch with 19%-260% higher F-measure than the five benchmarks. Conclusion: Our empirical results demonstrate that the review workload and other important information should be taken into consideration in finding reviewers who are potentially suitable for a newly-submitted patch. In addition, the results show the effectiveness of realizing this approach using a multi-objective search-based approach."
      >
        
          <span style="font-size: 100%">
            Workload-Aware Reviewer Recommendation using a Multi-objective Search-Based Approach
          </span>
        
      </span>
      <br />
      Wisam Haitham Abbood Al-Zubaidi, Patanamon Thongtanunam, <a href="http://www.uow.edu.au/~hoa/" target="_blank">Hoa Khanh Dam</a>, Chakkrit Tantithamthavorn, and Aditya Ghose<br />
      <i><small>(University of Wollongong, Australia; University of Melbourne, Australia; Monash University, Australia)</small></i><br />
      <span id="fsews20promisemain-p16-p-abs" style="display:none; border:1ex solid transparent; font-size: smaller;" >
              Background: Reviewer recommendation approaches have been proposed to provide automated support in finding suitable reviewers to review a given patch. However, they mainly focused on reviewer experience, and did not take into account the review workload, which is another important factor for a reviewer to decide if they will accept a review invitation. Aim: We set out to empirically investigate the feasibility of automatically recommending reviewers while considering the review workload amongst other factors. Method: We develop a novel approach that leverages a multi-objective meta-heuristic algorithm to search for reviewers guided by two objectives, i.e., (1) maximizing the chance of participating in a review, and (2) minimizing the skewness of the review workload distribution among reviewers. Results: Through an empirical study of 230,090 patches with 7,431 reviewers spread across four open source projects, we find that our approach can recommend reviewers who are potentially suitable for a newly-submitted patch with 19%-260% higher F-measure than the five benchmarks. Conclusion: Our empirical results demonstrate that the review workload and other important information should be taken into consideration in finding reviewers who are potentially suitable for a newly-submitted patch. In addition, the results show the effectiveness of realizing this approach using a multi-objective search-based approach.<br/>
        <br />
      </span>

  </div>
  <div style="margin-top: 1em;">
      <span
         
        title=""
      >
        
          <span style="font-size: 100%">
            Identifying Key Developers using Artifact Traceability Graphs
          </span>
        
      </span>
      <br />
      H. Alperen Cetin and Eray Tuzun<br />
      <i><small>(Bilkent University, Turkey)</small></i><br />
      <span id="fsews20promisemain-p34-p-abs" style="display:none; border:1ex solid transparent; font-size: smaller;" >
              <br/>
        <br />
      </span>

  </div>
  <div style="margin-top: 1em;">
      <span
         
        title=""
      >
        
          <span style="font-size: 100%">
            Fault-Insertion and Fault-Fixing: Analysing Developer Activity over Time
          </span>
        
      </span>
      <br />
      David Bowes, Giuseppe Destefanis, Tracy Hall, Jean Petric, and Marco Ortu<br />
      <i><small>(Lancaster University, UK; Brunel University, UK; University of Cagliari, Italy)</small></i><br />
      <span id="fsews20promisemain-p37-p-abs" style="display:none; border:1ex solid transparent; font-size: smaller;" >
              <br/>
        <br />
      </span>

  </div>
  <div style="margin-top: 1em;">
      <span
         
        title=""
      >
       
          <span style="font-size: 100%">
            An Exploratory Study on Applicability of Cross Project Defect Prediction Approaches to Cross-Company Effort Estimation
          </span>
       
      </span>
      <br />
      Sousuke Amasaki, Hirohisa Aman, and Tomoyuki Yokogawa<br />
      <i><small>(Okayama Prefectural University, Japan; Ehime University, Japan)</small></i><br />
      <span id="fsews20promisemain-p46-p-abs" style="display:none; border:1ex solid transparent; font-size: smaller;" >
              <br/>
        <br />
      </span>

  </div>
  <div style="margin-top: 1em;">
      <span
         
        title=""
      >
        
          <span style="font-size: 100%">
            SEERA: A Software Cost Estimation Dataset for Constrained Environments
          </span>
        
      </span>
      <br />
      Emtinan I. Mustafa and Rasha Osman<br />
      <i><small>(University of Khartoum, Sudan)</small></i><br />
      <span id="fsews20promisemain-p50-p-abs" style="display:none; border:1ex solid transparent; font-size: smaller;" >
              <br/>
        <br />
      </span>

  </div>
  <div style="margin-top: 1em;">
      <span
         
        title=""
      >
        
          <span style="font-size: 100%">
            Improving Real-World Vulnerability Characterization with Vulnerable Slices
          </span>
        
      </span>
      <br />
      Solmaz Salimi, Maryam Ebrahimzadeh, and Mehdi Kharrazi<br />
      <i><small>(Sharif University of Technology, Iran)</small></i><br />
      <span id="fsews20promisemain-p82-p-abs" style="display:none; border:1ex solid transparent; font-size: smaller;" >
              <br/>
        <br />
      </span>

  </div>
  <div style="margin-top: 1em;">
      <span
         
        title=""
      >
       
          <span style="font-size: 100%">
            Evaluating Hyper-parameter Tuning using Random Search in Support Vector Machines for Software Effort Estimation
          </span>
       
      </span>
      <br />
      Leonardo Villalobos-Arias, Christian Quesada-Lopez, Jose Guevara-Coto, Alexandra Martinez, and Marcelo Jenkins<br />
      <i><small>(University of Costa Rica, Costa Rica)</small></i><br />
      <span id="fsews20promisemain-p93-p-abs" style="display:none; border:1ex solid transparent; font-size: smaller;" >
              <br/>
        <br />
      </span>

  </div>


<hr>
<a name=cfp><h3>Call for papers</h3></a>
<p>
<img width=120 align=right style="padding: 5px;" src="img/cfp.png">
<p> <b> Technical papers:</b> (10 pages) 
PROMISE accepts a wide range of papers where AI tools have been applied to SE
such as predictive modeling  and other AI methods.
Both positive and negative results are
welcome, though negative results should still be based on rigorous
research and provide details on lessons learned. 
<p> <b> Industrial papers:</b> (2-4 pages) Results, challenges, lessons learned
     from industrial applications of software analytics.
<p> <b> New idea  papers:</b> (2-4 pages) Novel insights or ideas that may 
yet to be fully tested. 
<p> <b> Replication challenge-track papers:</b> (4 pages).
For details on this challenge track, see the <a href="replication.html">replication CFP</a>.
In summary, take some prior result in software analytics
    (of your choosing) and report the lessons learned while trying to reproduce it. 
      Note that such challenge track papers would be a suitable term
     project from university students.

</ul>
<h3> Publication and Attendance</h3>
<img width=80 align=right style="padding: 5px;" src="img/acm.png">
	<p>Accepted papers will be published in the ACM
	Digital Library within its International Conference Proceedings
	Series and will be available electronically via ACM Digital
	Library. 

	<p>Each accepted paper needs to have one registration
	at the full conference rate and be presented in person at
	the conference.

<h3>Topics</h3>
<p> PROMISE papers can explore any of the following topics (or more).</p>
<p>Application-oriented papers:
<ul>
<li>prediction of cost, effort, quality, defects, business value;
<li>quantification and prediction of other intermediate or final properties of interest in software development regarding people, process or product aspects;
<li>using predictive models and data analytics in different settings, e.g. lean/agile, waterfall, distributed, community-based software development;
<li>dealing with changing environments in software engineering tasks;
<li>dealing with multiple-objectives in software engineering tasks;
<li>using predictive models and software data analytics in policy and decision-making.
</ul>
<p>Ethically-aligned papers:
<ul>
<li> 
Can we apply and adjust our AI-for-SE tools (including predictive models)
to handle ethical non-functional requirements such as
inclusiveness, transparency, oversight and accountability,
privacy, security, reliability, safety, diversity and fairness? 
</li>
</ul>

<p>Theory-oriented papers:
<ul>
<li>model construction, evaluation, sharing and reusability;
<li>interdisciplinary and novel approaches to predictive modelling and data analytics that contribute to the theoretical body of knowledge in software engineering;
<li>verifying/refuting/challenging previous theory and results;
<li>combinations of predictive models and search-based software engineering;
<li>the effectiveness of human experts vs. automated models in predictions.
</ul>
<p>Data-oriented papers:
<ul>
<li>data quality, sharing, and privacy;
<li>curated data sets made available for the community to use;
<li>ethical issues related to data collection and sharing;
<li>metrics;
<li>tools and frameworks to support researchers and practitioners to collect data and construct models to share/repeat experiments and results.
</ul>
<p>Validity-oriented papers:
<ul>
<li>replication and repeatability of previous work using predictive modelling and data analytics in software engineering;
<li>assessment of measurement metrics for reporting the performance of predictive models;
<li>evaluation of predictive models with industrial collaborators.
</ul>

<h3>Green Open Access</h3>
<p>
Similar to other
leading SE conferences, PROMISE supports and encourages Green Open
Access, i.e., self-archiving. Authors can archive their papers on
their personal home page, an institutional repository of their
employer, or at an e-print server such as arXiv (preferred).
Also, given that PROMISE papers heavily rely on software
data, we would like to draw authors that leverage data scraped from
GitHub of GitHub's Terms of Service, which require that "publications
resulting from that research are open access". 
<p>
We also strongly encourage
authors to submit their tools and data to <a href="https://zenodo.org/">Zenodo</a>,
which adheres to FAIR (findable, accessible, interoperable and re-usable) principles
and provides DOI versioning.

    <hr>
	<a name=submit><h3>Submission (Double-Blind)</h3></a>
	<center>
	<p>

	<a href="https://promise20.hotcrp.com/paper/new"><img src="img/submit.png" width=200></a>
	</p></center>
<p>
<img align=right style="padding: 5px;" src="img/cfp1.png">
	PROMISE'20 submissions must meet the following criteria:
	<ul>
	<lI>Be original work, not published or under review elsewhere while being considered;
	<li>Conform to the ACM SIG proceedings template;
	<li>Not exceed 10 (4) pages for technical (challenge, industrial, new-ideas) papers including references;
	<li>Be written in English;
	<li>Be prepared for double blind review 
          <ul><li>Exception: for data-oriented papers, authors
            may elect not to use double blind by placing a footnote on page1 saying "Offered for single-blind review".</ul>
	<li>Be submitted via <a href="https://promise20.hotcrp.com/paper/new">HotCrp</a>. 
	<li
	<li>On submission,
 please choose the paper category appropriately; i.e. 
technical (main track, 10pages max);
Industrial (2-4 pages max);
New idea papers (2-4 pages max);
Replication challenge-track papers (4 pages max).
	</ul>
	<p> To satisfy the double blind requirement:
<ul>
	<li>	No authors names and affiliations from the body and metadata of the submitted paper;
	<li>	Self-citations are written in the third person;
	<li>	No reference to their personal, lab or university website; 
	<li>	No reference to personal accounts on GitHub, bitbucket, Google Drive, etc;
</ul>

	<p>
	Submissions will be peer reviewed by at least three experts
	from the international program committee. Submissions will
	be evaluated on the basis of their originality, importance
	of contribution, soundness, evaluation, quality, and
	consistency of presentation, and appropriate comparison to
	related work. 

    	  
			   
 	  
    <hr>
	<a name=program><h3>Program</h3></a>
TBD
   	

			</div><!-- end centercol -->
	
	<div>
	<br clear=both>
 			      
<hr>
<a name=history><h3>History</h3></a>
<p>
<img align=right width=300 style="padding: 5px;" src="https://github.com/promiseconf/promiseconf.github.io/raw/master/2020/img/history.png">
In this era of Github, GHtorrent, et al. it is hard to recall that
only a decade ago, it was difficult to access project data.
Nevertheless, that was the case.
<p>
Back in 2005 many people in the MSR field were analyzing large
amount of (public) open source data but kept the tools and processed
datasets to themselves as it was often considered a competitive
advantage. In fact, within the MSR community, it was not until 2013
that they started their Data Showcase track to encourage sharing
of data.
<p>
Meanwhile, back in 2005, the PROMISE CFP made such sharing an
explicit requirements when, in all caps, that document said:
<ul><em>
"SUBMISSIONS WHICH INCLUDE EMPIRICAL RESULTS BASED ON PUBLICLY
ACCESSIBLE DATASETS WILL BE GIVEN THE HIGHEST PRIORITY"
</em>
</ul>
<p> That emphasis of shared and
repeatable results was unthinkable at that time and many people
predicted that PROMISE would not last long. Tee hee. They were wrong.
Here is a list of the PROMISE meetings:
<ul><li>
<a href="http://promisedata.org/2019/">2019</a> |
<a href="http://promisedata.org/2018/">2018</a> |
<a href="http://promisedata.org/2017/">2017</a> |
<a href="http://promisedata.org/2016/">2016</a> |
<a href="http://promisedata.org/2015/">2015</a> |
<a href="http://promisedata.org/2014/">2014</a> |
<a href="http://promisedata.org/2013/">2013</a> |
<a href="http://promisedata.org/2012/">2012</a> |
<a href="https://dl.acm.org/citation.cfm?id=2020390&picked=prox">2011</a> |
<a href="https://dl.acm.org/citation.cfm?id=1868328&picked=prox">2010</a> |
<a href="https://dl.acm.org/citation.cfm?id=1540438&picked=prox">2009</a> |
<a href="https://dl.acm.org/citation.cfm?id=1370788&picked=prox">2008</a> |
<a href="https://dl.acm.org/citation.cfm?id=1268984&picked=prox">2007</a> |
<a href="https://dl.acm.org/citation.cfm?id=1083165&picked=prox">2005</a>
</ul>


<p>And here are some recent quotes from leading figures in SE about 
what was achieved by those PROMISE meetings:
<ul>
<li>
"I don't think any other contribution that is even remotely comparable
to (PROMISE)." 
<li>
"There are many factors that lead to the state-of-the-art
in mining software repositories, ... sharing and replicability in
the science of software engineering, but in my opinion, none played
a greater role than PROMISE."
<li>
"I can't think of a stronger contribution right now (to MSR), except
maybe the creation of the MSR community by Dr. Hassan." 
<li>
"PROMISE
makes research results reproducible. For example, according to
Robles et al. at MSR 2010, they found that over 95% of 171 papers
published at MSR were unreproducible, since their associated data
was no longer on-line. However, nearly all of the papers at the
PROMISE conference was reproducible since they were based on PROMISE
data. I believe this is a really significant contribution. " 
</ul>
<hr>
<br clear=both>
	</div>
		</div><!-- end main content area -->
				
	
	</div><!-- end wrapper1 -->

</div><!-- end wrapper2 -->
</div>	
</body>
</html>
