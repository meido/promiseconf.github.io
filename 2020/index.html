<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>PROMISE 2020: The International Conference on Predictive Models and Data Analytics in Software Engineering </title>
<meta name="description" content="PROMISE 2020: The International Conference on Predictive Models and Data Analytics in Software Engineering">
<meta name="keywords" content="PROMISE,predictive models,data analytics,software engineering">
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
<link href="img/3-col-fluid.css" rel="stylesheet" type="text/css" />
<link href="img/print.css" rel="stylesheet" type="text/css" media="print"/>

 <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Open Sans">
  

<!-- Please feel free to use this code in any way that you would like.  If you want to be cool, you can credit me - Mani Sheriar | www.ManiSheriar.com | Design@ManiSheriar.com.  Enjoy! -->

</head>

<body>
  <div id="outer">
    
  <div id="header"><!-- begin header -->
    
   <h1>PROMISE 2020</h1>
  <p>Inventing what's next  in software analytics<br> 
  An <a href="https://www.cs.ucdavis.edu/fse2020">FSE'20</a> co-located event.<br>
  http://tiny.cc/promise20<br>
  Nov 8, 2020<br>
    
  </div><!-- end header -->
<div id=menu>

	<div id="tabs4">
		<ul>
			<li><a href="https://www.cs.ucdavis.edu/fse2020/attending/venue/"><span><img src="https://www.freeiconspng.com/uploads/google-location-icon-16.png" align=top height=18> Venue</span></a></li>
			<li><a href="#keynotes"><span>Keynotes</span></a></li>
			<li><a href="#cfp" ><span>CFP</span></a></li>
			<li><a href="#special" ><span>Special issue </span></a></li>
			<li><a href="#submit" ><span>Submit</span></a></li>
			<li><a href="#program" ><span>Program </span></a></li>
			<li><a href="#history" ><span>History</span></a></li>
			<li><a href="img/promise20.pdf" ><span>Download flyer <img src="https://cdn.pixabay.com/photo/2016/06/15/14/54/download-1459070_960_720.png" align=top height=18></span></a></li>
			<li><a href="mailto:promise20@easychair.org" ><span>Contact</span></a></li>
		</ul>
	</div>     
</div>
<div id="wrapper1"><!-- sets background to white and creates full length leftcol-->
	
	<div id="wrapper2"><!-- sets background to white and creates full length rightcol-->
	
		<div id="maincol"><!-- begin main content area -->
				
		  <div id="leftcol"><!-- begin leftcol -->
		    <center>
		   
		    <time datetime="2014-09-20" class="icon">
		      <em>Tuesday</em>
		      <span>30</span>
		 
  <strong>June</strong>
     </time>
		    </center>
		  
			  
			    <ul>

<li>Submission: June 30, 2020
<li>Notification: July 30
<li>Camera ready: Aug 30
<li>Meeting: Nov 8
			    </ul>
<hr>
<center>
<a name="keynotes"><h3>Keynote Speakers</h3></a>
<small>
<p><img width=120 xalign=left style="padding: 5px;" src="img/bellamy.png"><br>
<b>Rachel Bellamy</b><br> IBM Research, NY:
<em>"Fair AI in Practice"</em><br>

<p><img width=120 ixalign=left style="padding: 5px;" src="img/briand.png"><br>
<b>Lionel Briand</b><br> U.Ottawa, Canada:
<em>"Natural Lanaguage and Software Requirements"</em><br>
</center>

<p>&nbsp;
<p><b><a name="bellamy">Dr. Rachel Bellamy: Fair AI in Practice</a></b>.
Fairness is an increasingly important concern as machine learning
models are used to support decision making in high-stakes applications
such as mortgage lending, hiring, and prison sentencing. This talk
will introduce an open source Python toolkit for algorithmic fairness,
AI Fairness 360 (AIF360). The main objectives of this toolkit are
to help facilitate the transition of fairness research algorithms
to use in an industrial setting and to provide a common framework
for fairness researchers to share and evaluate algorithms.
<em>Dr. Bellamy  is a Principle Research Scientist and manages
 the Human-AI Collaboration group at IBM T J Watson Research Center,
 Yorktown Heights, New York
Her team is currently working on the user experience for several
of IBM's AI projects, including the AI Fairness 360 toolkit
and rule-based machine-teaching for Watson Assistant. Rachel received
her doctorate in cognitive psychology from University of Cambridge,
UK in 1991. She holds many patents and has published more
than 70 research papers. For more, see her 
<a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-rachel">website</a>.
</em>

<p><b><a name="briand">Dr. Lionel Briand: NLP and Requirements</a></b>
Abstract, to be confirmed.
<em>
 Lionel C. Briand is professor of software engineering and has
 shared appointments between (1) The University of Ottawa, Canada
 and (2) The SnT centre for Security, Reliability, and Trust,
 University of Luxembourg. One of the founders of
 the 
 ICST conferencea
ge was also EiC of Empirical Software
 Engineering (Springer) for 13 years.
 Lionel was elevated to the grade of IEEE Fellow in 2010 for his
 work on testing object-oriented systems. He received an ERC
 Advanced grant in 2016- on the topic of modelling and testing
 cyber-physical systems- which is the most prestigious individual
 research award in the European Union. Most recently, he was awarded
 a Canada Research Chair (Tier 1) on "Intelligent Software Dependability
 and Compliance". His research interests include: software testing
 and verification, model-driven software development, applications
 of AI in software engineering, and empirical software engineering.
For more, see his <a href="https://sites.google.com/svv.lu/briand">website</a>.
</em>

	<hr>
	<center>
<a name=special><h3>Special Issue (at EMSE)</h3></a>
</center>
      	      <img width=80 align=right style="padding: 5px;" src="https://images.springer.com/sgw/journals/medium/10664.jpg">

<p>
<b>Inventing the next generation of software analytics.</b>

<p>Following on from this conference, we are organizing a 
special issue of the Empirical Software Engineering Journal.
<p>We
will ask authors
to comment on the success and failings of software analytics
over the last 20 years and will ask
"what and how can we do it better in future?". It is encouraged,
but not mandatory that authors 
explore the ethical issues raised in our CFP.

<p>The special issue will have the same guest editors as the co-PC chairs
of this conferences. Where possible, that special issue will also try to
use the same reviewers as PROMISE'20. The special issue will be open to
the entire SE community.

<p>Note that any PROMISE conference paper submitted to the special issue must be a 
significant extension to original conference content.

</small>			  
		  

				
				  </div><!-- end leftcol -->
				
			<div id="rightcol"><!-- begin rightcol -->
<center>
			  
<img src="img/p20.png" height=130>

<h3>ORGANIZING COMMITTEE </h3>
<small>
<b>general chair:</b>
<a href="http://www.cs.bham.ac.uk/~minkull/">Leandro Minku</a>, UK<br>
<b>co-pc-chairs:</b>
<a href="http://menzies.us">Tim Menzies</a>,   USA<br>
and <a href="https://cs.uwaterloo.ca/~m2nagapp/">Mei  Nagappan</a>,    Canada
<p><img src="img/minku.png" height=60>
 <img src="img/timm.png" height=60>&nbsp;&nbsp;&nbsp;<img src="img/mei.png" height=60>
<br><b>proceedings:</b>
<a href="http://www.research.lancs.ac.uk/portal/en/people/david-bowes(e0869507-92eb-4d5b-bbf9-af5f0ffe143c).html">David Bowes</a>, UK<br>
<b>publicity:</b>
<b></b><a href="https://www.igor.pro.br">Igor Steinmacher</a>,  USA<br>
and <b></b><a href="https://research.monash.edu/en/persons/xin-xia">Xin Xia</a>, AUS<p>
<img src="img/bowes.png" height=60>
<img src="img/igor.png" height=60>
<img src="img/xin.png" height=60>
 </p>
			      
			    <h3>Program Committee</h3>
	<table style="border:0;cell-padding:0; border-spacing: 0px; border-collapse:collapse;">
	
    <tr><td>Ho Khanh Dam </td><td> U.Woolongong, Aus</td></tr>
    <tr><td>Giuseppe Destefanis</td><td> Brunel, UK</td></tr>
    <tr><td>	 Carmine Gravino</td><td> U. Salerno, Italy</td></tr>
<tr><td>	 Tracy Hall</td><td>	 U. Lancaster, UK</td></tr>
<tr><td>	 Rachel Harrison</td><td>	 Oxford Brooks, UK</td></tr>
<tr><td>	 Yasutaka Kamei </td><td>	Naoyasu U., Japan</td></tr>
<tr><td>	 Lech Madeyski</td><td>	Wroclaw U., Polsand	</td></tr>
<tr><td>	 Shane McIntosh</td><td>	McGill U, Canada	</td></tr>
<tr><td>	 Jaechang Nam</td><td>	HGU,   Sth.Korea</td></tr>
<tr><td>	 Maleknaz Nayebi</td><td>	U.Toronto, Canada</td></tr>

<tr><td>	 Fabio Palomba</td><td> U.Zurich, Switzerland</td></tr>
<tr><td>	 Daniel Rodriguez</td><td>	U.   Alcala,  Spain	</td></tr>
<tr><td>	 Martin Shepperd</td><td> Brunel U., UK</td></tr>

<tr><td>			Jeff Tian</td><td>	Sth. Methodist U., USA</td></tr>
<tr><td>			Ayse Tosun</td><td>	ITU, Turkey</td></tr>

<tr><td>					Hironori Washizaki</td><td> Waseda U., Japan	</td></tr>
<tr><td>					Xin Xia</td><td>	Monash U, Australia		</td></tr>
<tr><td>					Zhou Yuming</td><td> Nanjing University, China</td></tr>
<tr><td>					and others</td><td> TBD</td></tr>
</table>

<h3>Steering Committee</h3>
</center>
        <ul>
          <li>General chair:
         <a href="http://www.cs.bham.ac.uk/~minkull/" target="_blank">Leandro Minku</a>, U.Birmingham</li>

          <li><a href="" target="_blank">David Bowes</a>, U.Central&nbsp;Lancashire</li>
	  <li><a href="http://www.khomh.net/">Foutse Khomh</a>, Ecole Polytechnique de Montreal</li>
          <li><a href="http://shanemcintosh.org/" target="_blank">Shane McIntosh</a>, McGill U.</li>
          <li><a href="http://www.cs.bham.ac.uk/~minkull/" target="_blank">Leandro Minku</a>, U. Birmingham</li>    
          <li><a href="http://www.scs.ryerson.ca/~avm/" target="_blank">Andriy Miranskyy</a>, Ryerson U.</li>
	  <li><a href="https://www.lancaster.ac.uk/scc/about-us/people/jean-petric">Jean Petric</a>, Lancaster University</li>
          <li><a href="http://das.encs.concordia.ca/members/emad-shihab/" target="_blank">Emad Shihab</a>, Concordia U.</li>
          <li><a href="https://web.itu.edu.tr/~tosunay/" target="_blank">Ayse Tosun</a>, Istanbul Tech.U.</li>
</ul>


   </center> 

<hr>
	

<a class="twitter-timeline" data-tweet-limit="10" data-chrome="nofooter noborders noscrollbar " href="https://twitter.com/promise_conf" data-widget-id="595679308884082688">Tweets by 
@promise_conf</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>

			  
			</div><!-- end righttcol -->
	</small>		
			<div id="centercol"><!-- begin centercol -->

  <a name=about></a>
<p>  Welcome to the 16th International PROMISE Conference on Analytics in SE.
For decades, 
<a href="#history">PROMISE has lead the SE field in open science</a>.
Here, we place a high premium on work
that can be repeated and/or improved and/or refuted by other researchers.
Hence we focus on those conclusions that can be reached automatically, via data mining.
Also, we strongly suggest that PROMISE authors share their
tools and data.  
<p>
Our  theme for PROMISE'20 is  <u>Ethical AI</u>.  
Models generated by AI-for-SE tools 
are 
assessed  by their predictive performance (via accuracy, recall, etc).
But groups like
the
IEEE, the Europeran Union, and Microsoft
now demand we
<a href="#ethics">assess
our tools using other
ethical criteria</a>. Hence, 
PROMISE'20 asks:
<ul><em>
Can we now apply and adjust our AI-for-SE tools (including predictive models)
to handle ethical non-functional requirements such as
inclusiveness, transparency, oversight and accountability,
privacy, security, reliability, safety, diversity and fairness? 
</em></ul>
<p>
To support our PROMISE'20 theme on Ethical AI:
<ul>
<li>We ask PROMISE'20 authors
to offer one (or more) section(s) in their paper on how their technology comments on ethical
non-functional requirements. 
For more details on thse kinds of requirements, see 
<a href="#ethics">notes on ethics</a>, below.
<span style="background-color: #ADFF2F;">This request is optional: PROMISE'20 is also 
	a venue for 
"classic" PROMISE research that explores predictive modeling</span>.
	<li> We have invited keynote speakers to address
these broader issues of AI-for-SE tools. 
<li> We are planning a lively "fish-bowl panel"
for this meeting where all participants can comment on ethics and AI-for-SE.
<li> This meeting will be followed by a <a href="#special">special issue of the Empirical Software Engineering journal</a>,
focusing on the issues of this conference.
</ul>

<hr>
<a name=cfp><h3>Call for papers</h3></a>
<p>
<img width=120 align=right style="padding: 5px;" src="img/cfp.png">
Historically, this conference has
focused on predictive modeling  and as that field has matured and broadened,
PROMISE now accepts a wide range of papers where AI tools have been applied to SE.
<p>
Both positive and negative results are
welcome, though negative results should still be based on rigorous
research and provide details on lessons learned. 

<p>Ethically-oriented papers:
<ul>
<li>It is encouraged,
<span style="background-color: #ADFF2F;">
but not mandatory, 
</span>
that somewhere in their paper
authors make some comment about the question posed above:
<ul><em>
Can we now apply and adjust our AI-for-SE tools (including predictive models)
to handle ethical non-functional requirements such as
inclusiveness, transparency, oversight and accountability,
privacy, security, reliability, safety, diversity and fairness? 
</em></ul>
<li>For some notes on these ethical non-functional requirements,
see our section  <a href="#ethics">"Notes on ethics"</a>.
</ul>
<p>Application-oriented papers:
<ul>
<li>prediction of cost, effort, quality, defects, business value;
<li>quantification and prediction of other intermediate or final properties of interest in software development regarding people, process or product aspects;
<li>using predictive models and data analytics in different settings, e.g. lean/agile, waterfall, distributed, community-based software development;
<li>dealing with changing environments in software engineering tasks;
<li>dealing with multiple-objectives in software engineering tasks;
<li>using predictive models and software data analytics in policy and decision-making.
</ul>
<p>Theory-oriented papers:
<ul>
<li>model construction, evaluation, sharing and reusability;
<li>interdisciplinary and novel approaches to predictive modelling and data analytics that contribute to the theoretical body of knowledge in software engineering;
<li>verifying/refuting/challenging previous theory and results;
<li>combinations of predictive models and search-based software engineering;
<li>the effectiveness of human experts vs. automated models in predictions.
</ul>
<p>Data-oriented papers:
<ul>
<li>data quality, sharing, and privacy;
<li>curated data sets made available for the community to use;
<li>ethical issues related to data collection and sharing;
<li>metrics;
<li>tools and frameworks to support researchers and practitioners to collect data and construct models to share/repeat experiments and results.
</ul>
<p>Validity-oriented papers:
<ul>
<li>replication and repeatability of previous work using predictive modelling and data analytics in software engineering;
<li>assessment of measurement metrics for reporting the performance of predictive models;
<li>evaluation of predictive models with industrial collaborators.
</ul>

<p>
Submissions can be of the following
kinds:

<ul>
<li>
Full papers: papers with novel and complete results.
<li>
Short papers: papers to disseminate on-going work and preliminary results for early feedback, or vision papers about the future of 
AI-for-SE tools (including predictive modeling).
</ul>
<p>
Similar to other
leading SE conferences, PROMISE supports and encourages Green Open
Access, i.e., self-archiving. Authors can archive their papers on
their personal home page, an institutional repository of their
employer, or at an e-print server such as arXiv (preferred).
Also, given that PROMISE papers heavily rely on software
data, we would like to draw authors that leverage data scraped from
GitHub of GitHub's Terms of Service, which require that "publications
resulting from that research are open access". 

<img width=80 align=right style="padding: 5px;" src="img/acm.png">
	<p>Accepted papers will be published in the ACM
	Digital Library within its International Conference Proceedings
	Series and will be available electronically via ACM Digital
	Library. 

	<p>Each accepted paper needs to have one registration
	at the full conference rate and be presented in person at
	the conference.

    <hr>
	<a name=submit><h3>Submission (Double-Blind)</h3></a>
<p>
<img align=right style="padding: 5px;" src="img/cfp1.png">
	PROMISE 2019 submissions must meet the following criteria:
	<ul>
	<lI>Be original work, not published or under review elsewhere while being considered;
	<li>Conform to the ACM SIG proceedings template;
	<li>Not exceed 10 (4) pages for full (short) papers including references;
	<li>Be written in English;
	<li>Be prepared for double blind review 
          <ul><li>Exception: for data-oriented papers, authors
            may elect not to use double blind by placing a footnote on page1 saying "Offered for single-blind review".</ul>
	<li>Be submitted via <a href=" https://easychair.org/conferences/?conf=promise20">EasyChair</a> (please choose the paper category appropriately; i.e. either long or short).
	</ul>
	<p>
	Submissions will be peer reviewed by at least three experts
	from the international program committee. Submissions will
	be evaluated on the basis of their originality, importance
	of contribution, soundness, evaluation, quality, and
	consistency of presentation, and appropriate comparison to
	related work. 

    	  
			   
 	  
    <hr>
	<a name=program><h3>Program</h3></a>
TBD
   	

			</div><!-- end centercol -->
	
	<div>
	<br clear=both>
 			      
<hr>
<a name=history><h3>History</h3></a>
<p>
<img align=right width=300 style="padding: 5px;" src="https://github.com/promiseconf/promiseconf.github.io/raw/master/2020/img/history.png">
In this era of Github, GHtorrent, et al. it is hard to recall that
only a decade ago, it was difficult to access project data.
Nevertheless, that was the case.
<p>
Back in 2005 many people in the MSR field were analyzing large
amount of (public) open source data but kept the tools and processed
datasets to themselves as it was often considered a competitive
advantage. In fact, within the MSR community, it was not until 2013
that they started their Data Showcase track to encourage sharing
of data.
<p>
Meanwhile, back in 2005, the PROMISE CFP made such sharing an
explicit requirements when, in all caps, that document said:
<ul><em>
"SUBMISSIONS WHICH INCLUDE EMPIRICAL RESULTS BASED ON PUBLICLY
ACCESSIBLE DATASETS WILL BE GIVEN THE HIGHEST PRIORITY"
</em>
</ul>
<p> That emphasis of shared and
repeatable results was unthinkable at that time and many people
predicted that PROMISE would not last long. Tee hee. They were wrong.
Here is a list of the PROMISE meetings:
<ul><li>
<a href="http://promisedata.org/2019/">2019</a> |
<a href="http://promisedata.org/2018/">2018</a> |
<a href="http://promisedata.org/2017/">2017</a> |
<a href="http://promisedata.org/2016/">2016</a> |
<a href="http://promisedata.org/2015/">2015</a> |
<a href="http://promisedata.org/2014/">2014</a> |
<a href="http://promisedata.org/2013/">2013</a> |
<a href="http://promisedata.org/2012/">2012</a> |
<a href="https://dl.acm.org/citation.cfm?id=2020390&picked=prox">2011</a> |
<a href="https://dl.acm.org/citation.cfm?id=1868328&picked=prox">2010</a> |
<a href="https://dl.acm.org/citation.cfm?id=1540438&picked=prox">2009</a> |
<a href="https://dl.acm.org/citation.cfm?id=1370788&picked=prox">2008</a> |
<a href="https://dl.acm.org/citation.cfm?id=1268984&picked=prox">2007</a> |
<a href="https://dl.acm.org/citation.cfm?id=1083165&picked=prox">2005</a>
</ul>


<p>And here are some recent quotes from leading figures in SE about 
what was achieved by those PROMISE meetings:
<ul>
<li>
"I don't think any other contribution that is even remotely comparable
to (PROMISE)." 
<li>
"There are many factors that lead to the state-of-the-art
in mining software repositories, ... sharing and replicability in
the science of software engineering, but in my opinion, none played
a greater role than PROMISE."
<li>
"I can't think of a stronger contribution right now (to MSR), except
maybe the creation of the MSR community by Dr. Hassan." 
<li>
"PROMISE
makes research results reproducible. For example, according to
Robles et al. at MSR 2010, they found that over 95% of 171 papers
published at MSR were unreproducible, since their associated data
was no longer on-line. However, nearly all of the papers at the
PROMISE conference was reproducible since they were based on PROMISE
data. I believe this is a really significant contribution. " 
</ul>
<hr>
<a name=ethics><h3>Notes on Ethics</h3></a>
<p>
<img align=right width=500 style="padding: 5px;" src="https://github.com/promiseconf/promiseconf.github.io/raw/master/2020/img/ethics.jpg">
    	 Many large international organizations are demanding
	 that AI models do more than just predict things. Now, it is expected
	 that they also contribute to other non-functional requirements.
	 <ul>
	 <li> In their document <a href="https://ethicsinaction.ieee.org">Ethically Aligned Design</a>, the IEEE lists these
	 goals for  implementing autonomous and intelligent systems (A/IS):
<ul>
	 <li><em>Human Rights:</em> A/IS shall be created and operated to respect, promote, and protect internationally recognized human rights.
	 <li><em>Well-being:</em> A/IS creators shall adopt increased human well-being as a primary success criterion for development.
	 <li><em>Data Agency:</em> A/IS creators shall empower individuals with the ability to access and securely share their data, to maintain peopleÃ¢ÂÂs capacity to have control over their identity.
	 <li><em>Effectiveness:</em> A/IS creators and operators shall provide evidence of the effectiveness and fitness for purpose of A/IS.
	 <li><em>Transparency:</em> The basis of a particular A/IS decision should always be discoverable.
	 <li><em>Accountability:</em> A/IS shall be created and operated to provide an unambiguous rationale for all decisions made.
	 <li><em>Awareness of Misuse:</em> A/IS creators shall guard against all potential misuses and risks of A/IS in operation.
</ul>

<li>Other organizations, like 
<a href="https://github.com/txt/ase19/blob/master/docs/REFS.md#microai-2019">Microsoft</a> offer their own principles for AI:
<ul>
<li><em>Transparency:</em> AI systems should be understandable
<li><em>Fairness:</em> AI systems should treat all people fairly
<li><em>Inclusiveness:</em> AI systems should empower everyone and engage people
<li><em>Reliability & Safety:</em> AI systems should perform reliably and safely
<li><em>Privacy & Security:</em> AI systems should be secure and respect privacy
<li><em>Accountability: </em> AI systems should have algorithmic accountability
</ul>
<li> Another statement of required ethics from AI systems comes from the 
<a href="https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai">European Union</a>:
<ul>
<li><em>Human agency and oversight:</em> AI systems should empower human beings, allowing them to make informed decisions and fostering their fundamental rights. At the same time, proper oversight mechanisms need to be ensured, which can be achieved through human-in-the-loop, human-on-the-loop, and human-in-command approaches
<li><em>Technical Robustness and safety:</em> AI systems need to be resilient and secure. They need to be safe, ensuring a fall back plan in case something goes wrong, as well as being accurate, reliable and reproducible. That is the only way to ensure that also unintentional harm can be minimized and prevented.
<li><em>Privacy and data governance:</em> besides ensuring full respect for privacy and data protection, adequate data governance mechanisms must also be ensured, taking into account the quality and integrity of the data, and ensuring legitimised access to data.
<li><em>Transparency:</em> the data, system and AI business models should be transparent. AI systems and their decisions should be explained in a manner adapted to the stakeholder concerned. Humans need to be aware that they are interacting with an AI system, and must be informed of the system's capabilities and limitations.
<li><em>Diversity, non-discrimination and fairness:</em> Unfair bias must be avoided, as it could could have multiple negative implications, from the marginalization of vulnerable groups, to the exacerbation of prejudice and discrimination. Fostering diversity, AI systems should be accessible to all, regardless of any disability, and involve relevant stakeholders throughout their entire life circle.
<li><em>Societal and environmental well-being:</em> AI systems should benefit all human beings, including future generations. It must hence be ensured that they are sustainable and environmentally friendly. Moreover, they should take into account the environment, including other living beings, and their social and societal impact should be carefully considered.
<li><em>Accountability:</em> Mechanisms should be put in place to ensure responsibility and accountability for AI systems and their outcomes. Auditability, which enables the assessment of algorithms, data and design processes plays a key role therein, especially in critical applications. Moreover, adequate an accessible redress should be ensured.
</ul>
	 </ul>
<p>
<img align=right width=500 src="https://github.com/promiseconf/promiseconf.github.io/raw/master/2020/img/ethics1.png">
Ethics is a rapidly evolving concept so it hardly surprising to say that mapping the stated ethical concerns of one organization into another is not easy. Nevertheless, the following tables shows one way we might map together these three sets of ethical concerns. Note that:

<ul>
<li>"accountability" and "transparency" appear in all three statements. Clearly these are concerns shared by many people.
<li>Missing from the Microsoft list is "effectiveness". Maybe Microsoft always assumes that their software is always effective?
<li>Assessed in terms of the Microsoft terminology, the IEEE goals or "well-being" and "awareness of misuse" are synonyms since they both reply on "fairness and "reliability and safely".
</ul>
<br clear=both>
	</div>
		</div><!-- end main content area -->
				
	
	</div><!-- end wrapper1 -->

</div><!-- end wrapper2 -->
</div>	
</body>
</html>
